Traceback (most recent call last):
  File "/Users/thomasryde/Documents/University/Kandidat/3. Semester/Machine Learning Operations/mlops/src/models/train_model.py", line 95, in <module>
    val_acc = val_correct / val_total
ZeroDivisionError: division by zero
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 411, 10, 10]          44,799
    PatchEmbedding-2             [-1, 101, 411]               0
         LayerNorm-3             [-1, 101, 411]             822
            Linear-4            [-1, 101, 1233]         506,763
           Dropout-5          [-1, 1, 101, 101]               0
            Linear-6             [-1, 101, 411]         169,332
           Dropout-7             [-1, 101, 411]               0
MultiHeadAttention-8             [-1, 101, 411]               0
           Dropout-9             [-1, 101, 411]               0
      ResidualAdd-10             [-1, 101, 411]               0
        LayerNorm-11             [-1, 101, 411]             822
           Linear-12             [-1, 101, 411]         169,332
             GELU-13             [-1, 101, 411]               0
          Dropout-14             [-1, 101, 411]               0
           Linear-15             [-1, 101, 411]         169,332
          Dropout-16             [-1, 101, 411]               0
          Dropout-17             [-1, 101, 411]               0
      ResidualAdd-18             [-1, 101, 411]               0
        LayerNorm-19             [-1, 101, 411]             822
           Linear-20            [-1, 101, 1233]         506,763
          Dropout-21          [-1, 1, 101, 101]               0
           Linear-22             [-1, 101, 411]         169,332
          Dropout-23             [-1, 101, 411]               0
MultiHeadAttention-24             [-1, 101, 411]               0
          Dropout-25             [-1, 101, 411]               0
      ResidualAdd-26             [-1, 101, 411]               0
        LayerNorm-27             [-1, 101, 411]             822
           Linear-28             [-1, 101, 411]         169,332
             GELU-29             [-1, 101, 411]               0
          Dropout-30             [-1, 101, 411]               0
           Linear-31             [-1, 101, 411]         169,332
          Dropout-32             [-1, 101, 411]               0
          Dropout-33             [-1, 101, 411]               0
      ResidualAdd-34             [-1, 101, 411]               0
        LayerNorm-35             [-1, 101, 411]             822
           Linear-36            [-1, 101, 1233]         506,763
          Dropout-37          [-1, 1, 101, 101]               0
           Linear-38             [-1, 101, 411]         169,332
          Dropout-39             [-1, 101, 411]               0
MultiHeadAttention-40             [-1, 101, 411]               0
          Dropout-41             [-1, 101, 411]               0
      ResidualAdd-42             [-1, 101, 411]               0
        LayerNorm-43             [-1, 101, 411]             822
           Linear-44             [-1, 101, 411]         169,332
             GELU-45             [-1, 101, 411]               0
          Dropout-46             [-1, 101, 411]               0
           Linear-47             [-1, 101, 411]         169,332
          Dropout-48             [-1, 101, 411]               0
          Dropout-49             [-1, 101, 411]               0
      ResidualAdd-50             [-1, 101, 411]               0
        LayerNorm-51             [-1, 101, 411]             822
           Linear-52            [-1, 101, 1233]         506,763
          Dropout-53          [-1, 1, 101, 101]               0
           Linear-54             [-1, 101, 411]         169,332
          Dropout-55             [-1, 101, 411]               0
MultiHeadAttention-56             [-1, 101, 411]               0
          Dropout-57             [-1, 101, 411]               0
      ResidualAdd-58             [-1, 101, 411]               0
        LayerNorm-59             [-1, 101, 411]             822
           Linear-60             [-1, 101, 411]         169,332
             GELU-61             [-1, 101, 411]               0
          Dropout-62             [-1, 101, 411]               0
           Linear-63             [-1, 101, 411]         169,332
          Dropout-64             [-1, 101, 411]               0
          Dropout-65             [-1, 101, 411]               0
      ResidualAdd-66             [-1, 101, 411]               0
        LayerNorm-67             [-1, 101, 411]             822
           Linear-68            [-1, 101, 1233]         506,763
          Dropout-69          [-1, 1, 101, 101]               0
           Linear-70             [-1, 101, 411]         169,332
          Dropout-71             [-1, 101, 411]               0
MultiHeadAttention-72             [-1, 101, 411]               0
          Dropout-73             [-1, 101, 411]               0
      ResidualAdd-74             [-1, 101, 411]               0
        LayerNorm-75             [-1, 101, 411]             822
           Linear-76             [-1, 101, 411]         169,332
             GELU-77             [-1, 101, 411]               0
          Dropout-78             [-1, 101, 411]               0
           Linear-79             [-1, 101, 411]         169,332
          Dropout-80             [-1, 101, 411]               0
          Dropout-81             [-1, 101, 411]               0
      ResidualAdd-82             [-1, 101, 411]               0
        LayerNorm-83             [-1, 101, 411]             822
           Linear-84            [-1, 101, 1233]         506,763
          Dropout-85          [-1, 1, 101, 101]               0
           Linear-86             [-1, 101, 411]         169,332
          Dropout-87             [-1, 101, 411]               0
MultiHeadAttention-88             [-1, 101, 411]               0
          Dropout-89             [-1, 101, 411]               0
      ResidualAdd-90             [-1, 101, 411]               0
        LayerNorm-91             [-1, 101, 411]             822
           Linear-92             [-1, 101, 411]         169,332
             GELU-93             [-1, 101, 411]               0
          Dropout-94             [-1, 101, 411]               0
           Linear-95             [-1, 101, 411]         169,332
          Dropout-96             [-1, 101, 411]               0
          Dropout-97             [-1, 101, 411]               0
      ResidualAdd-98             [-1, 101, 411]               0
        LayerNorm-99             [-1, 101, 411]             822
          Linear-100            [-1, 101, 1233]         506,763
         Dropout-101          [-1, 1, 101, 101]               0
          Linear-102             [-1, 101, 411]         169,332
         Dropout-103             [-1, 101, 411]               0
MultiHeadAttention-104             [-1, 101, 411]               0
         Dropout-105             [-1, 101, 411]               0
     ResidualAdd-106             [-1, 101, 411]               0
       LayerNorm-107             [-1, 101, 411]             822
          Linear-108             [-1, 101, 411]         169,332
            GELU-109             [-1, 101, 411]               0
         Dropout-110             [-1, 101, 411]               0
          Linear-111             [-1, 101, 411]         169,332
         Dropout-112             [-1, 101, 411]               0
         Dropout-113             [-1, 101, 411]               0
     ResidualAdd-114             [-1, 101, 411]               0
       LayerNorm-115             [-1, 101, 411]             822
          Linear-116            [-1, 101, 1233]         506,763
         Dropout-117          [-1, 1, 101, 101]               0
          Linear-118             [-1, 101, 411]         169,332
         Dropout-119             [-1, 101, 411]               0
MultiHeadAttention-120             [-1, 101, 411]               0
         Dropout-121             [-1, 101, 411]               0
     ResidualAdd-122             [-1, 101, 411]               0
       LayerNorm-123             [-1, 101, 411]             822
          Linear-124             [-1, 101, 411]         169,332
            GELU-125             [-1, 101, 411]               0
         Dropout-126             [-1, 101, 411]               0
          Linear-127             [-1, 101, 411]         169,332
         Dropout-128             [-1, 101, 411]               0
         Dropout-129             [-1, 101, 411]               0
     ResidualAdd-130             [-1, 101, 411]               0
       LayerNorm-131             [-1, 101, 411]             822
          Linear-132            [-1, 101, 1233]         506,763
         Dropout-133          [-1, 1, 101, 101]               0
          Linear-134             [-1, 101, 411]         169,332
         Dropout-135             [-1, 101, 411]               0
MultiHeadAttention-136             [-1, 101, 411]               0
         Dropout-137             [-1, 101, 411]               0
     ResidualAdd-138             [-1, 101, 411]               0
       LayerNorm-139             [-1, 101, 411]             822
          Linear-140             [-1, 101, 411]         169,332
            GELU-141             [-1, 101, 411]               0
         Dropout-142             [-1, 101, 411]               0
          Linear-143             [-1, 101, 411]         169,332
         Dropout-144             [-1, 101, 411]               0
         Dropout-145             [-1, 101, 411]               0
     ResidualAdd-146             [-1, 101, 411]               0
       LayerNorm-147             [-1, 101, 411]             822
          Linear-148            [-1, 101, 1233]         506,763
         Dropout-149          [-1, 1, 101, 101]               0
          Linear-150             [-1, 101, 411]         169,332
         Dropout-151             [-1, 101, 411]               0
MultiHeadAttention-152             [-1, 101, 411]               0
         Dropout-153             [-1, 101, 411]               0
     ResidualAdd-154             [-1, 101, 411]               0
       LayerNorm-155             [-1, 101, 411]             822
          Linear-156             [-1, 101, 411]         169,332
            GELU-157             [-1, 101, 411]               0
         Dropout-158             [-1, 101, 411]               0
          Linear-159             [-1, 101, 411]         169,332
         Dropout-160             [-1, 101, 411]               0
         Dropout-161             [-1, 101, 411]               0
     ResidualAdd-162             [-1, 101, 411]               0
       LayerNorm-163             [-1, 101, 411]             822
          Linear-164            [-1, 101, 1233]         506,763
         Dropout-165          [-1, 1, 101, 101]               0
          Linear-166             [-1, 101, 411]         169,332
         Dropout-167             [-1, 101, 411]               0
MultiHeadAttention-168             [-1, 101, 411]               0
         Dropout-169             [-1, 101, 411]               0
     ResidualAdd-170             [-1, 101, 411]               0
       LayerNorm-171             [-1, 101, 411]             822
          Linear-172             [-1, 101, 411]         169,332
            GELU-173             [-1, 101, 411]               0
         Dropout-174             [-1, 101, 411]               0
          Linear-175             [-1, 101, 411]         169,332
         Dropout-176             [-1, 101, 411]               0
         Dropout-177             [-1, 101, 411]               0
     ResidualAdd-178             [-1, 101, 411]               0
       LayerNorm-179             [-1, 101, 411]             822
          Linear-180            [-1, 101, 1233]         506,763
         Dropout-181          [-1, 1, 101, 101]               0
          Linear-182             [-1, 101, 411]         169,332
         Dropout-183             [-1, 101, 411]               0
MultiHeadAttention-184             [-1, 101, 411]               0
         Dropout-185             [-1, 101, 411]               0
     ResidualAdd-186             [-1, 101, 411]               0
       LayerNorm-187             [-1, 101, 411]             822
          Linear-188             [-1, 101, 411]         169,332
            GELU-189             [-1, 101, 411]               0
         Dropout-190             [-1, 101, 411]               0
          Linear-191             [-1, 101, 411]         169,332
         Dropout-192             [-1, 101, 411]               0
         Dropout-193             [-1, 101, 411]               0
     ResidualAdd-194             [-1, 101, 411]               0
TransformerEncoder-195             [-1, 101, 411]               0
VisionTransformer-196             [-1, 101, 411]               0
       LayerNorm-197                  [-1, 411]             822
          Linear-198                    [-1, 2]             824
ClassificationHead-199                    [-1, 2]               0
================================================================
Total params: 12,243,281
Trainable params: 12,243,281
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.05
Forward/backward pass size (MB): 66.81
Params size (MB): 46.70
Estimated Total Size (MB): 113.56
----------------------------------------------------------------
========= EPOCH 0 =========
0